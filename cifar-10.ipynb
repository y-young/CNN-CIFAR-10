{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91f82ce2-9443-4450-be53-e07ef47c7191",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "91f82ce2-9443-4450-be53-e07ef47c7191",
     "kernelId": "dc11dd5b-39c1-4ea4-9ad2-72484c80a613"
    }
   },
   "source": [
    "# CIFAR-10 Image Classification Based on CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d975759-c2f8-4e8f-9c57-546c84cbcf04",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "5d975759-c2f8-4e8f-9c57-546c84cbcf04",
     "kernelId": "dc11dd5b-39c1-4ea4-9ad2-72484c80a613"
    }
   },
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dde535-e0f0-46ad-869e-7cbe7879a655",
   "metadata": {
    "collapsed": true,
    "gradient": {
     "editing": false,
     "id": "72dde535-e0f0-46ad-869e-7cbe7879a655",
     "kernelId": "dc11dd5b-39c1-4ea4-9ad2-72484c80a613",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!pip install ipywidgets seaborn scikit-learn pandas torchinfo\n",
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c9d875-52e8-4c13-a262-0cbc70aaf4be",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "a6c9d875-52e8-4c13-a262-0cbc70aaf4be",
     "kernelId": "dc11dd5b-39c1-4ea4-9ad2-72484c80a613"
    }
   },
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af98cfe-b685-41a8-be5d-f27d2b98bf24",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "4af98cfe-b685-41a8-be5d-f27d2b98bf24",
     "kernelId": "dc11dd5b-39c1-4ea4-9ad2-72484c80a613",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "DATASET_PATH = \"./data\"\n",
    "OUTPUT_PATH = \"./cifar_net\"\n",
    "torch.manual_seed(2021)\n",
    "\n",
    "transformTrain = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(5),\n",
    "    transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "transformTest = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "batchSize = 128\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root=DATASET_PATH,\n",
    "                                        train=True,\n",
    "                                        download=True,\n",
    "                                        transform=transformTrain)\n",
    "trainloader = torch.utils.data.DataLoader(trainset,\n",
    "                                          batch_size=batchSize,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=0)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root=DATASET_PATH,\n",
    "                                       train=False,\n",
    "                                       download=True,\n",
    "                                       transform=transformTest)\n",
    "testloader = torch.utils.data.DataLoader(testset,\n",
    "                                         batch_size=batchSize,\n",
    "                                         shuffle=False,\n",
    "                                         num_workers=0)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse',\n",
    "           'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc076b6-2d92-458c-b406-d45ed826ca9e",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "ecc076b6-2d92-458c-b406-d45ed826ca9e",
     "kernelId": "dc11dd5b-39c1-4ea4-9ad2-72484c80a613"
    }
   },
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c3bd86-7ff1-4034-bc1c-0a353329e227",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "d7c3bd86-7ff1-4034-bc1c-0a353329e227",
     "kernelId": "dc11dd5b-39c1-4ea4-9ad2-72484c80a613",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Layer(nn.Module):\n",
    "    def __init__(self, inChannel, outChannel, kernelSize=3):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(inChannel,\n",
    "                              outChannel,\n",
    "                              kernelSize,\n",
    "                              stride=1,\n",
    "                              padding=1)\n",
    "        self.bn = nn.BatchNorm2d(outChannel)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.relu(self.bn(self.conv(x)))\n",
    "\n",
    "class Net(nn.Module):\n",
    "    cfg = [(3, 32, 3), (32, 32, 3), 'M', (32, 64, 3), 'M', (64, 128, 3), 'M', (128, 128, 3), 'M']\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = self.buildLayers()\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(512, 256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def buildLayers(self):\n",
    "        layers = []\n",
    "        for l in self.cfg:\n",
    "            if l == 'M':\n",
    "                layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "            else:\n",
    "                layers.append(Layer(l[0], l[1], l[2]))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55353193-cf3e-4991-9d0b-bf1407bf019a",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "55353193-cf3e-4991-9d0b-bf1407bf019a",
     "kernelId": "dc11dd5b-39c1-4ea4-9ad2-72484c80a613"
    }
   },
   "source": [
    "## Detect GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98940b3-bb7c-44f0-99f9-0db8a973ecdd",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "a98940b3-bb7c-44f0-99f9-0db8a973ecdd",
     "kernelId": "dc11dd5b-39c1-4ea4-9ad2-72484c80a613",
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc13b45e-5f07-49b1-98a4-7016178f64eb",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "dc13b45e-5f07-49b1-98a4-7016178f64eb",
     "kernelId": "dc11dd5b-39c1-4ea4-9ad2-72484c80a613"
    }
   },
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704ceaf2-90d5-425d-b4e1-3e03c3b8186b",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "704ceaf2-90d5-425d-b4e1-3e03c3b8186b",
     "kernelId": "dc11dd5b-39c1-4ea4-9ad2-72484c80a613",
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def train(dataloader, model, lossFunction, optimizer, epoch: int) -> Tuple[float, float]:\n",
    "    trainingLoss = 0.0\n",
    "    batches = len(dataloader)\n",
    "    correctCount = 0\n",
    "    total = len(dataloader.dataset)\n",
    "    model.train()\n",
    "\n",
    "    for batch, (inputs, labels) in enumerate(dataloader, 0):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = lossFunction(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        trainingLoss += loss.item()\n",
    "        correctCount += (predicted == labels.data).sum().item()\n",
    "\n",
    "        if batch % 100 == 99:  # print every 100 mini-batches\n",
    "            print('[Epoch %3d Batch %3d] Loss: %.3f' % (epoch, batch + 1, loss.item()))\n",
    "\n",
    "    trainingLoss /= batches\n",
    "    accuracy = 100.0 * correctCount / total\n",
    "    print(\"[Epoch %3d] Training Loss: %0.3f, Accuracy: %0.2f %%\" % (epoch, trainingLoss, accuracy))\n",
    "    return (trainingLoss, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a82fc25-84f7-45af-a0dd-8547c65cbd41",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "8a82fc25-84f7-45af-a0dd-8547c65cbd41",
     "kernelId": "dc11dd5b-39c1-4ea4-9ad2-72484c80a613",
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def test(dataloader, model, lossFunction) -> Tuple[float, float]:\n",
    "    testLoss = 0.0\n",
    "    batches = len(dataloader)\n",
    "    correctCount = 0\n",
    "    total = len(dataloader.dataset)\n",
    "    model.eval()\n",
    "\n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = model(images)\n",
    "            loss = lossFunction(outputs, labels)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            testLoss += loss.item()\n",
    "            correctCount += (predicted == labels).sum().item()\n",
    "\n",
    "    testLoss /= batches\n",
    "    accuracy = 100.0 * correctCount / total\n",
    "    print(\"Test Loss: %0.3f, Accuracy: %0.2f %%\" % (testLoss, accuracy))\n",
    "    return (testLoss, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3923053a-1e9a-4846-8e8a-0b62c2fc8287",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "3923053a-1e9a-4846-8e8a-0b62c2fc8287",
     "kernelId": "dc11dd5b-39c1-4ea4-9ad2-72484c80a613",
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluate(dataloader, model, classes):\n",
    "    # prepare to count predictions for each class\n",
    "    correctPred = {classname: 0 for classname in classes}\n",
    "    totalPred = {classname: 0 for classname in classes}\n",
    "    yPred = []\n",
    "    yTrue = []\n",
    "    model.eval()\n",
    "\n",
    "    # again no gradients needed\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            yPred.extend(predictions.view(-1).detach().cpu().numpy())\n",
    "            yTrue.extend(labels.view(-1).detach().cpu().numpy())\n",
    "            # collect the correct predictions for each class\n",
    "            for label, prediction in zip(labels, predictions):\n",
    "                if label == prediction:\n",
    "                    correctPred[classes[label]] += 1\n",
    "                totalPred[classes[label]] += 1\n",
    "\n",
    "    # print accuracy for each class\n",
    "    for classname, correct_count in correctPred.items():\n",
    "        accuracy = 100 * float(correct_count) / totalPred[classname]\n",
    "        print(\"Accuracy for class {:5s} is: {:.1f} %\".format(\n",
    "            classname, accuracy))\n",
    "\n",
    "    confusionMatrix = confusion_matrix(yTrue, yPred)\n",
    "    print(confusionMatrix)\n",
    "    confusionMatrix = confusionMatrix / confusionMatrix.sum(axis=1)\n",
    "    matrix = pd.DataFrame(confusionMatrix, classes, classes)\n",
    "    plt.figure(figsize = (9,6))\n",
    "    sns.heatmap(matrix, annot=True, cmap=\"Greens\")\n",
    "    plt.title(\"Confusion Matrix\", fontsize=14)\n",
    "    plt.xlabel(\"prediction\", fontsize=12)\n",
    "    plt.ylabel(\"label (ground truth)\", fontsize=12)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba247dd-0f51-450f-8604-5e3c15d431c8",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "0ba247dd-0f51-450f-8604-5e3c15d431c8",
     "kernelId": "dc11dd5b-39c1-4ea4-9ad2-72484c80a613",
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plotGraph(training, test, metrics):\n",
    "    plt.plot(range(1,\n",
    "                   len(training) + 1),\n",
    "             training,\n",
    "             label=\"train\",\n",
    "             c='r',\n",
    "             marker='.')\n",
    "    plt.plot(range(1, len(test) + 1), test, label=\"test\", c='b', marker='.')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metrics)\n",
    "    plt.title(\"Training & Test \" + metrics)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8520ab-5243-4dc2-a73c-8d7b2a87c48d",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "ac8520ab-5243-4dc2-a73c-8d7b2a87c48d",
     "kernelId": "dc11dd5b-39c1-4ea4-9ad2-72484c80a613",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "net = Net()\n",
    "net.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "# optimizer = optim.SGD(net.parameters(), lr=0.008, momentum=0.9)\n",
    "epochs = 100\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "\n",
    "trainingLosses = []\n",
    "trainingAccuracies = []\n",
    "testLosses = []\n",
    "testAccuracies = []\n",
    "\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    loss, accuracy = train(trainloader, net, criterion, optimizer, epoch + 1)\n",
    "    trainingLosses.append(loss)\n",
    "    trainingAccuracies.append(accuracy)\n",
    "\n",
    "    loss, accuracy = test(testloader, net, criterion)\n",
    "    testLosses.append(loss)\n",
    "    testAccuracies.append(accuracy)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "print(\"Finished Training\")\n",
    "plotGraph(trainingLosses, testLosses, \"Loss\")\n",
    "plotGraph(trainingAccuracies, testAccuracies, \"Accuracy\")\n",
    "\n",
    "torch.save(net.state_dict(), OUTPUT_PATH)\n",
    "\n",
    "print(\"Evaluation Result on Test:\")\n",
    "evaluate(testloader, net, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb664418-a587-46df-9fa0-a84f38fc1559",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "eb664418-a587-46df-9fa0-a84f38fc1559",
     "kernelId": "dc11dd5b-39c1-4ea4-9ad2-72484c80a613",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# net.load_state_dict(torch.load(\"./cifar_net\"))\n",
    "evaluate(testloader, net, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89973277-6d65-4662-9ee6-7b072666d951",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "89973277-6d65-4662-9ee6-7b072666d951",
     "kernelId": "dc11dd5b-39c1-4ea4-9ad2-72484c80a613",
     "source_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "Net                                      --\n",
       "├─Sequential: 1-1                        --\n",
       "│    └─Layer: 2-1                        --\n",
       "│    │    └─Conv2d: 3-1                  896\n",
       "│    │    └─BatchNorm2d: 3-2             64\n",
       "│    └─Layer: 2-2                        --\n",
       "│    │    └─Conv2d: 3-3                  9,248\n",
       "│    │    └─BatchNorm2d: 3-4             64\n",
       "│    └─MaxPool2d: 2-3                    --\n",
       "│    └─Layer: 2-4                        --\n",
       "│    │    └─Conv2d: 3-5                  18,496\n",
       "│    │    └─BatchNorm2d: 3-6             128\n",
       "│    └─MaxPool2d: 2-5                    --\n",
       "│    └─Layer: 2-6                        --\n",
       "│    │    └─Conv2d: 3-7                  73,856\n",
       "│    │    └─BatchNorm2d: 3-8             256\n",
       "│    └─MaxPool2d: 2-7                    --\n",
       "│    └─Layer: 2-8                        --\n",
       "│    │    └─Conv2d: 3-9                  147,584\n",
       "│    │    └─BatchNorm2d: 3-10            256\n",
       "│    └─MaxPool2d: 2-9                    --\n",
       "├─Linear: 1-2                            131,328\n",
       "├─Dropout: 1-3                           --\n",
       "├─Linear: 1-4                            16,448\n",
       "├─Linear: 1-5                            650\n",
       "=================================================================\n",
       "Total params: 399,274\n",
       "Trainable params: 399,274\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 22.36\n",
       "=================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 1.48\n",
       "Params size (MB): 1.60\n",
       "Estimated Total Size (MB): 3.09\n",
       "================================================================="
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(net, (1, 3, 32, 32), col_names=(\"num_params\",))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857bb8fd-a3a0-4d85-a2fa-b3f2db4dde8e",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": true,
     "id": "857bb8fd-a3a0-4d85-a2fa-b3f2db4dde8e",
     "kernelId": "dc11dd5b-39c1-4ea4-9ad2-72484c80a613",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "def softmax(x):\n",
    "    y = np.exp(x - np.max(x))\n",
    "    f_x = y / np.sum(np.exp(x))\n",
    "    return f_x\n",
    "\n",
    "def predictImage(image, model):\n",
    "    model.eval()\n",
    "    imageTensor = transform(image).float()\n",
    "    imageTensor = imageTensor.unsqueeze_(0)\n",
    "    input = Variable(imageTensor)\n",
    "    input = input.to(device)\n",
    "    output = model(input)\n",
    "    index = output.data.cpu().numpy()\n",
    "    print(softmax(index))\n",
    "    index = index.argmax()\n",
    "    return index\n",
    "\n",
    "\n",
    "image = Image.open('cat.jpg')\n",
    "index = predictImage(image, net)\n",
    "print(classes[index])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
